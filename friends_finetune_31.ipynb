{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "friends_finetune_31.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb14cbc375034747a216e81294f0bc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b4d76e4ebc34df89b3279b9643d99fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0491b9ab995e473f8cc68ff70e1ed5f5",
              "IPY_MODEL_941f8a5cd7b344aea23e6ffaeb6a1514"
            ]
          }
        },
        "9b4d76e4ebc34df89b3279b9643d99fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0491b9ab995e473f8cc68ff70e1ed5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b4d33877ebe5449ca725be9e8ed133e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faa561031c754798afaa06638ee7a1fd"
          }
        },
        "941f8a5cd7b344aea23e6ffaeb6a1514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2ff38d3a5194a4bba552bb88d6da9a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 841kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab392c14bb194627a813392b1a099b2d"
          }
        },
        "b4d33877ebe5449ca725be9e8ed133e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faa561031c754798afaa06638ee7a1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2ff38d3a5194a4bba552bb88d6da9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab392c14bb194627a813392b1a099b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76c895bdc0e241dda0c2f417ce5e5f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_76e8837cd44b434fa1e02ef6be045750",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5059b502697e4974b23435275d734d59",
              "IPY_MODEL_60ff801a94d541fcac6d41bd3a2b23cb"
            ]
          }
        },
        "76e8837cd44b434fa1e02ef6be045750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5059b502697e4974b23435275d734d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6dd3fd74bce4dd8b987c2d8627e27f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e54414c78cc44b9b85b9656bf58e32e"
          }
        },
        "60ff801a94d541fcac6d41bd3a2b23cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6d7867d7a204c36895273ebfa21ae5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.42kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fef63ccd0a545c79df44112836c22c9"
          }
        },
        "e6dd3fd74bce4dd8b987c2d8627e27f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e54414c78cc44b9b85b9656bf58e32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6d7867d7a204c36895273ebfa21ae5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fef63ccd0a545c79df44112836c22c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3af6c84fcfd6456894c14928ea12fe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3fc6dea29a6548f59d13f15d5edc179b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc1d4010527e4e5b9811a4dcac0cc145",
              "IPY_MODEL_cbc59dccfc474ab8ace7297b793d42db"
            ]
          }
        },
        "3fc6dea29a6548f59d13f15d5edc179b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc1d4010527e4e5b9811a4dcac0cc145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5b2e380b03a4f0685bccc99a6f6f897",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5d374d93f75477fbe2893fbfdc9fa2b"
          }
        },
        "cbc59dccfc474ab8ace7297b793d42db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b59b69b6b353443498ff2e474dd4cfaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [15:03&lt;00:00, 487kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fa8acf83311488a9015890cfc04664b"
          }
        },
        "c5b2e380b03a4f0685bccc99a6f6f897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5d374d93f75477fbe2893fbfdc9fa2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b59b69b6b353443498ff2e474dd4cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fa8acf83311488a9015890cfc04664b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PDas2206/BERT_emotion_analysis/blob/master/friends_finetune_31.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tUoHe9FRhs"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr7BCHS-nIRW",
        "scrolled": true,
        "outputId": "8059dace-815b-4722-8ea8-c64ebf71311d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 14.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=7cc69b3759f82e31879e412a81569ae211f41e655dc987d2a75a1ed7c5273099\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB5Dij6JuItX",
        "outputId": "7ca3f2ac-dbd9-4e5f-a54f-9e1d0d9b4b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " from google.colab import drive\n",
        " drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjnJEwKnISB",
        "outputId": "6d2d628b-3567-4c2f-f422-14818c5dcb18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uorMX_zrnISM",
        "scrolled": true,
        "outputId": "bfbd21d2-3b1d-43d0-dbb0-e19dc01fb2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLcetMjZFjSH"
      },
      "source": [
        "## Load and Preprocess Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dal0ggBcYdD"
      },
      "source": [
        "Dataset will be tokenized then split into training and validation sets. The validation set will be used to monitor training. For testing a separate test set will be loaded for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ecREc7GnISW",
        "scrolled": true,
        "outputId": "3bb81100-f081-443e-ca3d-88d4b73c8dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/friends_train_nofilter.csv') #jigsaw-toxic-comment-classification-challenge\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anger</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4100000</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>also I was the point person on my companys tr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5000000</td>\n",
              "      <td>The Interviewer</td>\n",
              "      <td>You mustve had your hands full.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>That I did. That I did.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5000000</td>\n",
              "      <td>The Interviewer</td>\n",
              "      <td>So lets talk a little bit about your duties.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000030</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>My duties?  All right.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   annotation          speaker  ... sadness  surprise\n",
              "0     4100000         Chandler  ...       0         0\n",
              "1     5000000  The Interviewer  ...       0         0\n",
              "2     5000000         Chandler  ...       0         0\n",
              "3     5000000  The Interviewer  ...       0         0\n",
              "4     2000030         Chandler  ...       0         1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhWrzX7nITB",
        "outputId": "df4f4d0e-6577-493b-edea-d8b366cb4f03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Unique comments: ', df.utterance.nunique() == df.shape[0])\n",
        "print('Null values: ', df.isnull().values.any())\n",
        "# df[df.isna().any(axis=1)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique comments:  False\n",
            "Null values:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkKpz_9eJRt7",
        "outputId": "b80f3f40-92a8-40ef-8170-ad386af7d26c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('average sentence length: ', df.utterance.str.split().str.len().mean())\n",
        "print('stdev sentence length: ', df.utterance.str.split().str.len().std())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average sentence length:  7.792727961367294\n",
            "stdev sentence length:  6.231603847035365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVI59S9VaAfB",
        "outputId": "e49715e8-92e3-4190-e4c3-5727394758dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cols = df.columns\n",
        "label_cols = list(cols[3:])\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label columns:  ['neutral', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgA5qQgYIBZ",
        "outputId": "349ae7d2-cf2e-44a2-b921-600ab77b46c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n",
        "print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " neutral     4752\n",
            "anger        513\n",
            "disgust      240\n",
            "fear         185\n",
            "joy         1283\n",
            "sadness      351\n",
            "surprise    1220\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " neutral      5809\n",
            "anger       10048\n",
            "disgust     10321\n",
            "fear        10376\n",
            "joy          9278\n",
            "sadness     10210\n",
            "surprise     9341\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFpSd4JzaAae"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DF3ddjej5vd",
        "outputId": "47370c6e-aab0-4faf-f2e6-d97ab1ea9d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anger</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Lydia</td>\n",
              "      <td>The Celtics.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Monica</td>\n",
              "      <td>I</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>Check this out.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1010003</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Can we turn the TV off? Okay? Do we really wan...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4000001</td>\n",
              "      <td>Mark</td>\n",
              "      <td>Its for me.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   annotation   speaker  ... surprise         one_hot_labels\n",
              "0     5000000     Lydia  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "1     5000000    Monica  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "2     5000000  Chandler  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "3     1010003    Monica  ...        0  [0, 0, 1, 0, 0, 0, 0]\n",
              "4     4000001      Mark  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlhHifh5bW7e"
      },
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.utterance.values)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMHfElhGJzc"
      },
      "source": [
        "Load the pretrained tokenizer that corresponds to your choice in model. e.g.,\n",
        "\n",
        "```\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhVr8SziL_PY"
      },
      "source": [
        "In order to avoid memory issues with Google Colab, I enforce a max_length of 100 tokens. Note that some sentences may not adequately represent each label because of this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNsEu-vUur-4",
        "outputId": "a0f4d154-332c-4ddd-8bc4-e653da118cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "eb14cbc375034747a216e81294f0bc72",
            "9b4d76e4ebc34df89b3279b9643d99fc",
            "0491b9ab995e473f8cc68ff70e1ed5f5",
            "941f8a5cd7b344aea23e6ffaeb6a1514",
            "b4d33877ebe5449ca725be9e8ed133e5",
            "faa561031c754798afaa06638ee7a1fd",
            "e2ff38d3a5194a4bba552bb88d6da9a2",
            "ab392c14bb194627a813392b1a099b2d"
          ]
        }
      },
      "source": [
        "max_length = 100\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n",
        "encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
        "print('tokenizer outputs: ', encodings.keys())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb14cbc375034747a216e81294f0bc72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6CCLSjfur-9"
      },
      "source": [
        "input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
        "token_type_ids = encodings['token_type_ids'] # token type ids\n",
        "attention_masks = encodings['attention_mask'] # attention masks"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSOFbThlYcpb",
        "outputId": "e3957a7b-4f1f-40fa-bd10-eb0ba22f1d5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n",
        "label_counts = df.one_hot_labels.astype(str).value_counts()\n",
        "one_freq = label_counts[label_counts==1].keys()\n",
        "one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n",
        "print('df label indices with only one instance: ', one_freq_idxs)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df label indices with only one instance:  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ7CoOag_r7"
      },
      "source": [
        "# Gathering single instance inputs to force into the training set after stratified split\n",
        "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n",
        "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJUGkpdmFCgh"
      },
      "source": [
        "Tokenizing the dev set for validation purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zUpm6ZNFTh0",
        "outputId": "e1c520f2-21fe-42b3-8774-44642d54532c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_v = pd.read_csv('/content/drive/My Drive/friends_dev_nofilter.csv') #jigsaw-toxic-comment-classification-challenge\n",
        "df_v.head()\n",
        "print('Unique comments: ', df_v.utterance.nunique() == df_v.shape[0])\n",
        "print('Null values: ', df_v.isnull().values.any())\n",
        "# df[df.isna().any(axis=1)]\n",
        "print('average sentence length: ', df_v.utterance.str.split().str.len().mean())\n",
        "print('stdev sentence length: ', df_v.utterance.str.split().str.len().std())\n",
        "cols = df_v.columns\n",
        "label_cols = list(cols[3:])\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)\n",
        "print('Count of 1 per label: \\n', df_v[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n",
        "print('Count of 0 per label: \\n', df_v[label_cols].eq(0).sum())\n",
        "df_v = df_v.sample(frac=1).reset_index(drop=True) #shuffle rows\n",
        "df_v['one_hot_labels'] = list(df_v[label_cols].values)\n",
        "df_v.head()\n",
        "\n",
        "validation_ids = encodings['input_ids'] # tokenized and encoded sentences"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique comments:  False\n",
            "Null values:  False\n",
            "average sentence length:  7.703735144312394\n",
            "stdev sentence length:  5.996005719851644\n",
            "Label columns:  ['neutral', 'anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
            "Count of 1 per label: \n",
            " neutral     491\n",
            "anger        85\n",
            "disgust      23\n",
            "fear         29\n",
            "joy         123\n",
            "sadness      62\n",
            "surprise    151\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " neutral      687\n",
            "anger       1093\n",
            "disgust     1155\n",
            "fear        1149\n",
            "joy         1055\n",
            "sadness     1116\n",
            "surprise    1027\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9PxAt48HRRj"
      },
      "source": [
        "Be sure to handle all classes during validation using \"stratify\" during train/validation split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPFaq4ufnIT2"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "\n",
        "#train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n",
        "#                                                           random_state=2020, test_size=0.10, stratify = labels)\n",
        "train_inputs=input_ids\n",
        "train_labels=labels\n",
        "train_token_types=token_type_ids\n",
        "train_masks=attention_masks\n",
        "\n",
        "\n",
        "validation_inputs=validation_ids\n",
        "validation_labels=labels\n",
        "validation_token_types=token_type_ids\n",
        "validation_masks=attention_masks\n",
        "\n",
        "# Add one frequency data to train data\n",
        "train_inputs.extend(one_freq_input_ids)\n",
        "train_labels.extend(one_freq_labels)\n",
        "train_masks.extend(one_freq_attention_masks)\n",
        "train_token_types.extend(one_freq_token_types)\n",
        "\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "validation_token_types = torch.tensor(validation_token_types)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRnuLna-nIT4"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFRnP_ZTBFa"
      },
      "source": [
        "torch.save(validation_dataloader,'validation_data_loader')\n",
        "torch.save(train_dataloader,'train_data_loader')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncGteBuSFuZM"
      },
      "source": [
        "## Load Model & Set Params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dL-Bz_NrGj"
      },
      "source": [
        "Load the appropriate model below, each model already contains a single dense layer for classification on top.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "BERT:\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "\n",
        "XLNet:\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n",
        "\n",
        "RoBERTa:\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk4k16DnIT6",
        "outputId": "ef3c66a5-f6e5-4ef3-a2b6-6914db1e75b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "76c895bdc0e241dda0c2f417ce5e5f00",
            "76e8837cd44b434fa1e02ef6be045750",
            "5059b502697e4974b23435275d734d59",
            "60ff801a94d541fcac6d41bd3a2b23cb",
            "e6dd3fd74bce4dd8b987c2d8627e27f4",
            "4e54414c78cc44b9b85b9656bf58e32e",
            "c6d7867d7a204c36895273ebfa21ae5a",
            "5fef63ccd0a545c79df44112836c22c9",
            "3af6c84fcfd6456894c14928ea12fe6a",
            "3fc6dea29a6548f59d13f15d5edc179b",
            "dc1d4010527e4e5b9811a4dcac0cc145",
            "cbc59dccfc474ab8ace7297b793d42db",
            "c5b2e380b03a4f0685bccc99a6f6f897",
            "d5d374d93f75477fbe2893fbfdc9fa2b",
            "b59b69b6b353443498ff2e474dd4cfaf",
            "8fa8acf83311488a9015890cfc04664b"
          ]
        }
      },
      "source": [
        "# Load model, the pretrained model will include a single linear classification layer on top for classification. \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76c895bdc0e241dda0c2f417ce5e5f00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3af6c84fcfd6456894c14928ea12fe6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGE4gv9qfhRG"
      },
      "source": [
        "Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsV8zwWYnIT9"
      },
      "source": [
        "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOomZIEIoHOL"
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRQQZ8zIFzLW"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLZmEC_oKo3",
        "outputId": "ac772e9c-967f-402f-dd2a-d1b948abe887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    #print(\"labels: \",b_labels)\n",
        "    print(\"num of labels: \",num_labels)\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    #outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    #target = Variable(torch.LongTensor([7]))\n",
        "    #outputs.shape\n",
        "    #loss = outputs[0]\n",
        "    #loss=outputs.loss\n",
        "    #logits = outputs[1]\n",
        "    #loss_func=nn.CrossEntropyLoss()\n",
        "    #print(b_labels.view(-1,num_labels))\n",
        "    #loss=loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.view(-1))\n",
        "    #loss = loss_func(logits.view(-1,num_labels),b_labels.view(-1,num_labels))\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.50\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "Train loss: 0.27473289742390555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [04:27<08:54, 267.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  67.03077128013854\n",
            "Flat Validation Accuracy:  60.04166272133321\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "Train loss: 0.18863286474140029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [08:56<04:27, 267.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  74.41705529646903\n",
            "Flat Validation Accuracy:  67.50307736009847\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "num of labels:  7\n",
            "Train loss: 0.15418755548958332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 3/3 [13:26<00:00, 268.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  82.50338128611828\n",
            "Flat Validation Accuracy:  76.64993845279803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiBeiBSRoOuz"
      },
      "source": [
        "torch.save(model.state_dict(), 'bert_model_toxic')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7dd2GE3F4yK"
      },
      "source": [
        "## Load and Preprocess Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Q7hC4GFOLJ",
        "outputId": "0edd9dc6-e3b4-4749-fde9-9936b8fa0f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "test_df = pd.read_csv('/content/drive/My Drive/friends_test_nofilter.csv')\n",
        "#test_labels_df = pd.read_csv('test_labels.csv')\n",
        "#test_df = test_df.merge(test_labels_df, on='id', how='left')\n",
        "test_label_cols = list(test_df.columns[3:])\n",
        "print('Null values: ', test_df.isnull().values.any()) #should not be any null sentences or labels\n",
        "print('Same columns between train and test: ', label_cols == test_label_cols) #columns should be the same\n",
        "test_df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null values:  False\n",
            "Same columns between train and test:  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anger</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000030</td>\n",
              "      <td>Mark</td>\n",
              "      <td>Why do all youre coffee mugs have numbers on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2100011</td>\n",
              "      <td>Rachel</td>\n",
              "      <td>Oh. Thats so Monica can keep track. That way ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000020</td>\n",
              "      <td>Rachel</td>\n",
              "      <td>Y'know what?</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Ross</td>\n",
              "      <td>It didnt.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1300010</td>\n",
              "      <td>Frank</td>\n",
              "      <td>Okay, so what you used to have with Rachel, is...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   annotation speaker  ... sadness  surprise\n",
              "0     2000030    Mark  ...       0         1\n",
              "1     2100011  Rachel  ...       0         0\n",
              "2     3000020  Rachel  ...       0         0\n",
              "3     5000000    Ross  ...       0         0\n",
              "4     1300010   Frank  ...       0         0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rjCrMGpYxz",
        "outputId": "4fc500ae-2d06-4795-9bd6-f6721d62f96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\n",
        "test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n",
        "test_df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>neutral</th>\n",
              "      <th>anger</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000030</td>\n",
              "      <td>Mark</td>\n",
              "      <td>Why do all youre coffee mugs have numbers on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2100011</td>\n",
              "      <td>Rachel</td>\n",
              "      <td>Oh. Thats so Monica can keep track. That way ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000020</td>\n",
              "      <td>Rachel</td>\n",
              "      <td>Y'know what?</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5000000</td>\n",
              "      <td>Ross</td>\n",
              "      <td>It didnt.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1300010</td>\n",
              "      <td>Frank</td>\n",
              "      <td>Okay, so what you used to have with Rachel, is...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   annotation speaker  ... surprise         one_hot_labels\n",
              "0     2000030    Mark  ...        1  [0, 0, 0, 0, 0, 0, 1]\n",
              "1     2100011  Rachel  ...        0  [0, 0, 0, 0, 0, 0, 0]\n",
              "2     3000020  Rachel  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "3     5000000    Ross  ...        0  [1, 0, 0, 0, 0, 0, 0]\n",
              "4     1300010   Frank  ...        0  [0, 0, 0, 0, 1, 0, 0]\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a41OmU2i7qp"
      },
      "source": [
        "# Gathering input data\n",
        "test_labels = list(test_df.one_hot_labels.values)\n",
        "test_comments = list(test_df.utterance.values)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amySMO8EQzf2",
        "outputId": "183ca981-ab52-4c08-9c9b-1eec79f7d925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Encoding input data\n",
        "test_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\n",
        "test_input_ids = test_encodings['input_ids']\n",
        "test_token_type_ids = test_encodings['token_type_ids']\n",
        "test_attention_masks = test_encodings['attention_mask']"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqOfi9fkRaRN"
      },
      "source": [
        "# Make tensors out of data\n",
        "test_inputs = torch.tensor(test_input_ids)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_masks = torch.tensor(test_attention_masks)\n",
        "test_token_types = torch.tensor(test_token_type_ids)\n",
        "# Create test dataloader\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "# Save test dataloader\n",
        "torch.save(test_dataloader,'test_data_loader')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFTWxCA_GBau"
      },
      "source": [
        "## Prediction and Metics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPvrL6OFSQvf"
      },
      "source": [
        "# Test\n",
        "\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "#track variables\n",
        "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "# Predict\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "  with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label = pred_label.to('cpu').numpy()\n",
        "    b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
        "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "true_labels = [item for sublist in true_labels for item in sublist]\n",
        "# Converting flattened binary values to boolean values\n",
        "true_bools = [tl==1 for tl in true_labels]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQeGWqeMzAoZ"
      },
      "source": [
        "We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcZUcYOxxmM",
        "outputId": "ff3237ae-74e4-44c7-bc0e-d8caa05582ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
        "\n",
        "# Print and save classification report\n",
        "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
        "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
        "clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n",
        "pickle.dump(clf_report, open('/content/drive/My Drive/classification_report_nofilter_joy.txt','wb')) #save report\n",
        "print(clf_report)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.654871546291808\n",
            "Test Flat Accuracy:  0.5886396526772794 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     neutral       0.78      0.75      0.76      1287\n",
            "       anger       0.52      0.31      0.39       161\n",
            "     disgust       0.00      0.00      0.00        68\n",
            "        fear       0.00      0.00      0.00        32\n",
            "         joy       0.76      0.44      0.56       304\n",
            "     sadness       0.91      0.12      0.21        85\n",
            "    surprise       0.51      0.67      0.58       286\n",
            "\n",
            "   micro avg       0.71      0.61      0.65      2223\n",
            "   macro avg       0.50      0.33      0.36      2223\n",
            "weighted avg       0.69      0.61      0.63      2223\n",
            " samples avg       0.49      0.49      0.49      2223\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rLqrHK87eir"
      },
      "source": [
        "## Output Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJBkRdGN1hzx",
        "outputId": "711ce1f3-a079-4a14-fc46-6b0c873ee341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "idx2label = dict(zip(range(7),label_cols))\n",
        "print(idx2label)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'neutral', 1: 'anger', 2: 'disgust', 3: 'fear', 4: 'joy', 5: 'sadness', 6: 'surprise'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZUglV_A4BF_"
      },
      "source": [
        "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
        "true_label_idxs, pred_label_idxs=[],[]\n",
        "for vals in true_bools:\n",
        "  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
        "for vals in pred_bools:\n",
        "  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGhXM3R4a91"
      },
      "source": [
        "# Gathering vectors of label names using idx2label\n",
        "true_label_texts, pred_label_texts = [], []\n",
        "for vals in true_label_idxs:\n",
        "  if vals:\n",
        "    true_label_texts.append([idx2label[val] for val in vals])\n",
        "  else:\n",
        "    true_label_texts.append(vals)\n",
        "\n",
        "for vals in pred_label_idxs:\n",
        "  if vals:\n",
        "    pred_label_texts.append([idx2label[val] for val in vals])\n",
        "  else:\n",
        "    pred_label_texts.append(vals)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HaqV6pn_HCG"
      },
      "source": [
        "# Decoding input ids to comment text\n",
        "utterances = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7kk0Mgl1L-T",
        "outputId": "0241a26f-76ae-46b5-8549-82ed171a0149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Converting lists to df\n",
        "comparisons_df = pd.DataFrame({'utterance': utterances, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
        "comparisons_df.to_csv('/content/drive/My Drive/comparisons_nofilter_joy.csv')\n",
        "comparisons_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>pred_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>why do all youre coffee mugs have numbers on t...</td>\n",
              "      <td>[surprise]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oh . thats so monica can keep track . that way...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>y ' know what ?</td>\n",
              "      <td>[neutral]</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>it didnt .</td>\n",
              "      <td>[neutral]</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>okay , so what you used to have with rachel , ...</td>\n",
              "      <td>[joy]</td>\n",
              "      <td>[neutral]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           utterance true_labels pred_labels\n",
              "0  why do all youre coffee mugs have numbers on t...  [surprise]          []\n",
              "1  oh . thats so monica can keep track . that way...          []   [neutral]\n",
              "2                                    y ' know what ?   [neutral]   [neutral]\n",
              "3                                         it didnt .   [neutral]   [neutral]\n",
              "4  okay , so what you used to have with rachel , ...       [joy]   [neutral]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWFd18u3zlF8"
      },
      "source": [
        "## Bonus - Optimizing threshold value for micro F1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6mDy1lw0S4y"
      },
      "source": [
        "Doing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHlhb2lvar8V",
        "outputId": "d08fc4e4-891f-43ea-8168-14c7742a3377",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n",
        "\n",
        "macro_thresholds = np.array(range(1,10))/10\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in macro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n",
        "\n",
        "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in micro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_f1_idx = np.argmax(f1_results) #best threshold value\n",
        "\n",
        "# Printing and saving classification report\n",
        "print('Best Threshold: ', micro_thresholds[best_f1_idx])\n",
        "print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n",
        "print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n",
        "\n",
        "best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n",
        "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
        "pickle.dump(clf_report_optimized, open('/content/drive/My Drive/classification_report_optimized.txt','wb'))\n",
        "print(clf_report_optimized)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Threshold:  0.3\n",
            "Test F1 Accuracy:  0.6681175190424374\n",
            "Test Flat Accuracy:  0.599493487698987 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     neutral       0.74      0.81      0.78      1287\n",
            "       anger       0.40      0.49      0.44       161\n",
            "     disgust       0.00      0.00      0.00        68\n",
            "        fear       0.00      0.00      0.00        32\n",
            "         joy       0.66      0.60      0.63       304\n",
            "     sadness       0.65      0.24      0.34        85\n",
            "    surprise       0.45      0.74      0.56       286\n",
            "\n",
            "   micro avg       0.65      0.69      0.67      2223\n",
            "   macro avg       0.41      0.41      0.39      2223\n",
            "weighted avg       0.63      0.69      0.65      2223\n",
            " samples avg       0.55      0.56      0.55      2223\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBg6UCYAYtIe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}